<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jonathan Rahn - AI Research & Engineering</title>
    <link rel="canonical" href="https://jorahn.github.io/">
    <meta name="robots" content="index, follow">
    <link rel="icon" type="image/jpeg" href="avatar.jpg">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="main-nav">
        <div class="nav-container">
            <a href="/" class="nav-brand">
                <img src="avatar.jpg" alt="Jonathan Rahn" class="nav-avatar">
                <span>Jonathan Rahn</span>
            </a>
            <button class="nav-toggle" id="navToggle">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <div class="nav-links" id="navLinks">
                <a href="/" class="nav-link active">About</a>
                <a href="/research/" class="nav-link">Research</a>
                <a href="/blog/" class="nav-link">Blog</a>
                <a href="https://github.com/jorahn" class="nav-link" target="_blank">GitHub</a>
                <a href="https://huggingface.co/jrahn" class="nav-link" target="_blank">HuggingFace</a>
            </div>
        </div>
    </nav>

    <header>
        <div class="header-content">
            <div class="header-text">
                <h1>Chess AI Through Language Models: Strategic Reasoning Without Search</h1>
                <p class="subtitle">AI Lab Lead, Drees & Sommer</p>
            </div>
        </div>
    </header>

    <main>
        <section class="content-section">
            <h2>Research Overview</h2>
            <p>This work explores transformer-based strategic reasoning through chess as a testbed, demonstrating that language models can develop sophisticated game-playing capabilities without traditional search algorithms. In collaboration with <a href="https://laion.ai/notes/rook" target="_blank">LAION</a>, we've developed a progression of models that challenge fundamental assumptions about how AI systems learn strategic thinking.</p>
            
            <div class="highlight-box">
                <p><strong>Core hypothesis:</strong> Complex strategic reasoning can emerge from next-token prediction when models are trained on appropriately structured strategic data.</p>
            </div>
        </section>

        <section class="content-section">
            <h2>The ROOK Project Evolution</h2>
            
            <div class="project-card">
                <h3>RookWorld-RLVR (2025) - RL Fine-Tuning with Verification <span class="badge">Current</span></h3>
                <p>Active development integrating GRPO (Reinforcement Learning with Verifiable Rewards) for enhanced reasoning capabilities.</p>
                <div class="project-links">
                    <a href="https://github.com/jorahn/rookworld-trl" target="_blank" class="project-link">Repo Transformers & TRL</a>
                    <a href="https://github.com/jorahn/rookworld-rlvr" target="_blank" class="project-link">Repo PyTorch</a>
                </div>
            </div>

            <div class="project-card">
                <h3>RookWorld-LM (2024) - Unified Agent+Environment</h3>
                <p><strong>124M params:</strong> Unified chess policy and world model in a single transformer architecture.<br>
                Post: <a href="https://laion.ai/notes/rook/" target="_blank">ROOK: REASONING OVER ORGANIZED KNOWLEDGE</a></p>
                
                <div class="collaboration">
                    <strong>Collaboration:</strong> <a href="https://scholar.google.com/citations?user=p1FuAMkAAAAJ&hl=en" target="_blank">Jenia Jitsev</a> (LAION/JSC), <a href="https://scholar.google.com/citations?user=rv0MJuAAAAAJ&hl=en" target="_blank">Qi Sun</a> (Tokyo Tech/Sakana AI)
                </div>
                
                <div class="metrics">
                    <h4>Multi-task Performance:</h4>
                    <ul>
                        <li>üèÜ <strong>32.1% Checkmate-in-One accuracy</strong> - outperforms ChessGPT-Base (26.5%) with 24x fewer parameters (124M vs 3B, Feng et al. NeurIPS'23)</li>
                        <li>99.9% environment simulation accuracy</li>
                        <li>26.2% overall action accuracy</li>
                    </ul>
                </div>
                
                <div class="project-links">
                    <a href="https://huggingface.co/jrahn/RookWorld-LM-124M" target="_blank" class="project-link">Model</a>
                    <a href="https://huggingface.co/datasets/jrahn/rookworld_7m" target="_blank" class="project-link">Dataset</a>
                </div>

                <div class="demo-link">
                    <a href="/research/rookworld-demo/?model=rookworld" class="btn-primary">Try Interactive Demo</a>
                    <p style="margin-top: 10px; font-size: 0.9em;">Browser-based inference using ONNX Runtime (WASM). Downloads 285MB model for client-side generation.</p>
                </div>

                <p class="significance"><strong>Significance:</strong> Enables closed-loop self-play without external engines</p>
            </div>

            <div class="project-card">
                <h3>ROOK-LM (2024) - Chain-of-Thought Reasoning</h3>
                <p><strong>124M params:</strong> Implementation of reasoning traces for chess, incorporating position analysis ‚Üí candidate evaluation ‚Üí move selection.</p>

                <ul>
                    <li><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/lfsm/rook-40m" target="_blank">rook_40m</a> (6B tokens, generated on Tsubame 4.0)</li>
                    <li><strong>Architecture:</strong> GPT-2 with custom chess tokenization</li>
                    <li><strong>Performance:</strong> 22.2% action accuracy, 24.4% Checkmate-in-One with reasoning traces</li>
                    <li><strong>Technical Details:</strong> <a href="https://laion.ai/notes/rook/" target="_blank">LAION Research Note</a></li>
                </ul>

                <div class="project-links">
                    <a href="https://huggingface.co/jrahn/ROOK-LM-124M" target="_blank" class="project-link">Model</a>
                </div>

                <div class="demo-link">
                    <a href="/research/rookworld-demo/?model=rook-lm" class="btn-primary">Try Interactive Demo</a>
                    <p style="margin-top: 10px; font-size: 0.9em;">Browser-based inference using ONNX Runtime (WASM). Downloads 285MB model for client-side generation.</p>
                </div>
            </div>

            <div class="project-card">
                <h3>ROOK-CLF (2024) - Decoder-based Behavioral Cloning</h3>
                <p><strong>9M params:</strong> Reproduction of Google DeepMind's <a href="https://arxiv.org/abs/2402.04494" target="_blank">"Grandmaster-Level Chess Without Search"</a> methodology using LLaMA-based decoder.</p>

                <ul>
                    <li><strong>Performance:</strong> 49% action accuracy, 57% on Checkmate-in-One</li>
                    <li><strong>Achievement:</strong> Demonstrated searchless chess AI feasibility with minimal parameters</li>
                    <li><strong>Model:</strong> <a href="https://huggingface.co/jrahn/ROOK-CLF-9m" target="_blank">Available on HuggingFace</a></li>
                </ul>

                <div class="demo-link">
                    <a href="/research/rook-clf-demo/" class="btn-primary">Try Interactive Demo</a>
                    <p style="margin-top: 10px; font-size: 0.9em;">Browser-based inference using ONNX Runtime (WASM/WebGPU). Downloads 9MB quantized model for client-side generation.</p>
                </div>
            </div>

            <div class="project-card">
                <h3>LAION Strategic Game Dataset (2023) - Dataset Engineering</h3>
                <p>Contributed to the <a href="https://laion.ai/blog/strategic-game-dataset/" target="_blank">LAION Strategic Game Dataset</a> project, responding to their call for participation to enhance AI models' strategic planning capabilities through game-based synthetic datasets. Developed chess-to-text transformation tools for dataset generation as part of this community effort exploring strategic reasoning in language models.</p>

                <ul>
                    <li><strong>Contribution:</strong> Chess dataset generation and transformation pipeline</li>
                    <li><strong>Code:</strong> <a href="https://github.com/jorahn/chess-to-text" target="_blank">chess-to-text repository</a></li>
                    <li><strong>Project Scale:</strong> 3.2 billion chess games, 608 billion moves via Stockfish self-play</li>
                    <li><strong>Impact:</strong> Foundation work that evolved into the ROOK project research</li>
                </ul>
            </div>

            <div class="project-card">
                <h3>YoloChess (2022) - Encoder-based Behavioral Cloning</h3>
                <p><strong>87M params (Custom DeBERTaV2-base, Vocab Size 500):</strong> Two-stage training approach: initial masked language modeling (MLM) pretraining on FEN representations, followed by supervised fine-tuning on a sequence classification objective for move prediction. Established baseline performance and identified key challenges in chess representation for transformer architectures.</p>

                <ul>
                    <li><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/jrahn/yolochess_lichess-elite_2211" target="_blank">yolochess_lichess-elite_2211</a></li>
                    <li><strong>Architecture:</strong> DeBERTa v2 with custom FEN tokenization and classification head</li>
                    <li><strong>Training:</strong> MLM pretraining ‚Üí Supervised fine-tuning for sequence classification</li>
                    <li><strong>W&B Logs:</strong> <a href="https://wandb.ai/jrahn/chessv62/reports/Training-V6b-2-Fine-Tuning---VmlldzoyNjgzODk3" target="_blank">View W&B Training Logs</a></li>
                </ul>
            </div>
        </section>

        <section class="content-section">
            <h2>Technical Contributions</h2>
            
            <div class="contribution-grid">
                <div class="contribution">
                    <h3>Novel Architectures</h3>
                    <ul>
                        <li>Unified world modeling: Simultaneous policy and environment simulation in transformers</li>
                        <li>Strategic tokenization: Custom representations for structured game states</li>
                        <li>Multi-task scaling: Consistent performance improvements with unified training objectives</li>
                    </ul>
                </div>
                
                <div class="contribution">
                    <h3>Dataset Engineering</h3>
                    <ul>
                        <li>Large-scale annotation: 40M+ positions annotated with Stockfish 16.1 on supercomputing infrastructure</li>
                        <li>Multi-format datasets: Support for classification, autoregressive, and multi-task learning</li>
                        <li>Reproducible pipelines: Full data generation code and methodology documentation</li>
                    </ul>
                </div>
                
                <div class="contribution">
                    <h3>Open Science Impact</h3>
                    <p>All models, datasets, and code publicly available. Contributing to democratization of strategic AI research.</p>
                </div>
            </div>
        </section>

        <section class="content-section">
            <h2>Research Context</h2>
            <p>Background spans early esports content management with leading German clan mTw during competitive gaming's formative years, founding and scaling startup readmore.de (CEO, 2005) which earned two esports awards before acquisition by publishing house Computec Media AG in 2007. Academic foundation in neuro-informatics (University of L√ºbeck) and business economics & management (Witten/Herdecke University, IPADE Mexico DF, Masters 2012), followed by games publishing startup experience and transition into data-driven digital performance marketing. Continuous learning includes fast.ai deep learning (2018), INRIA scikit-learn MOOC (2021), and Mastering LLMs with Hamel Husain (Maven, 2024). Recognition includes the SEOday 2023 best speaker award for GPT-4 content generation innovation. Active contributor to HuggingFace ecosystem (transformers, datasets, evaluate) and open source frameworks. Current work at Drees & Sommer, building the AI Lab & exploring applications in construction and real estate optimization.</p>
        </section>

        <section class="content-section">
            <h2>Research Implications</h2>
            <p>The RookWorld results suggest that:</p>
            
            <ol class="implications-list">
                <li><strong>Search-free strategic AI</strong> is viable with appropriate training data</li>
                <li><strong>Unified architectures</strong> can efficiently handle multiple strategic reasoning tasks</li>
                <li><strong>Chain-of-thought training</strong> improves both performance and interpretability</li>
                <li><strong>Language model paradigms</strong> apply effectively to structured strategic domains</li>
            </ol>
            
            <p>These findings have implications beyond chess for any domain requiring sequential decision-making under complex constraints.</p>
        </section>
    </main>

    <footer>
        <div class="footer-content">
            <p>&copy; 2024 Jonathan Rahn. All rights reserved.</p>
        </div>
    </footer>

    <script>
        // Mobile navigation toggle
        document.getElementById('navToggle').addEventListener('click', function() {
            this.classList.toggle('active');
            document.getElementById('navLinks').classList.toggle('active');
        });

        // Close mobile menu when clicking a link
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', () => {
                document.getElementById('navToggle').classList.remove('active');
                document.getElementById('navLinks').classList.remove('active');
            });
        });
    </script>
</body>
</html>
